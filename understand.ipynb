{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"edgeface_s_gamma_05\"\n",
    "checkpoint_path = f'checkpoints/{model_name}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimmFRWrapperV2(\n",
      "  (model): EdgeNeXt(\n",
      "    (stem): Sequential(\n",
      "      (0): Conv2d(3, 48, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): EdgeNeXtStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            )\n",
      "            (pos_embd): PositionalEncodingFourier(\n",
      "              (token_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (norm_xca): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=288, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(96, 160, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0-1): 2 x Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)\n",
      "            )\n",
      "            (norm_xca): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=480, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(160, 304, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0-2): 3 x Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76)\n",
      "            )\n",
      "            (norm_xca): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=912, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_pre): Identity()\n",
      "    (head): NormMlpClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "      (norm): LayerNorm2d((304,), eps=1e-06, elementwise_affine=True)\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (pre_logits): Identity()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): LoRaLin(\n",
      "        (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "        (linear2): Linear(in_features=152, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38649/2124090954.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from backbones import get_model\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"edgeface_s_gamma_05\"  # Replace with your model name\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = get_model(model_name)\n",
    "\n",
    "# Load the state dictionary\n",
    "checkpoint_path = f'checkpoints/{model_name}.pt'\n",
    "state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Print the model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor shape: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor of shape (batch_size, 3, 112, 112) to pass through the model\n",
    "input_tensor = torch.randn(1, 3, 112, 112)  # Batch size of 1\n",
    "\n",
    "# Pass the tensor through the model\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "# Print the output tensor shape\n",
    "print(f\"Output tensor shape: {output_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimmFRWrapperV2(\n",
      "  (model): EdgeNeXt(\n",
      "    (stem): Sequential(\n",
      "      (0): Conv2d(3, 48, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): EdgeNeXtStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=48, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=192, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=192, out_features=24, bias=False)\n",
      "                (linear2): Linear(in_features=24, out_features=48, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            )\n",
      "            (pos_embd): PositionalEncodingFourier(\n",
      "              (token_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (norm_xca): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=288, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=96, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=384, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=384, out_features=48, bias=False)\n",
      "                (linear2): Linear(in_features=48, out_features=96, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(96, 160, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): ConvBlock(\n",
      "            (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0-1): 2 x Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)\n",
      "            )\n",
      "            (norm_xca): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=480, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=160, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=640, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=640, out_features=80, bias=False)\n",
      "                (linear2): Linear(in_features=80, out_features=160, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): EdgeNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(160, 304, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvBlock(\n",
      "            (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBlock(\n",
      "            (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): SplitTransposeBlock(\n",
      "            (convs): ModuleList(\n",
      "              (0-2): 3 x Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76)\n",
      "            )\n",
      "            (norm_xca): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (xca): CrossCovarianceAttn(\n",
      "              (qkv): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=912, bias=True)\n",
      "              )\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): LoRaLin(\n",
      "                (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=1216, bias=True)\n",
      "              )\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): LoRaLin(\n",
      "                (linear1): Linear(in_features=1216, out_features=152, bias=False)\n",
      "                (linear2): Linear(in_features=152, out_features=304, bias=True)\n",
      "              )\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_pre): Identity()\n",
      "    (head): NormMlpClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "      (norm): LayerNorm2d((304,), eps=1e-06, elementwise_affine=True)\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (pre_logits): Identity()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): LoRaLin(\n",
      "        (linear1): Linear(in_features=304, out_features=152, bias=False)\n",
      "        (linear2): Linear(in_features=152, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total parameters: 3652520\n",
      "Trainable parameters: 3652520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38649/3769512966.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from backbones import get_model\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"edgeface_s_gamma_05\"  # Replace with your model name\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = get_model(model_name)\n",
    "\n",
    "# Load the state dictionary\n",
    "checkpoint_path = f'checkpoints/{model_name}.pt'\n",
    "state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the model structure and parameters\n",
    "print(model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# Load the edgenext_x_small model\n",
    "model_name = \"edgenext_small\"\n",
    "model = timm.create_model(model_name, pretrained=True)  # Use pretrained=True to load pretrained weights\n",
    "\n",
    "# Print the model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# List all ResNet-34 variants with pretrained weights\n",
    "resnet34_variants = timm.list_models('resnet34*', pretrained=True)\n",
    "print(resnet34_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet34 = timm.create_model(\"resnet34\", pretrained=True)\n",
    "model_resnet34.pretrained_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhomnhom0/miniforge3/envs/face_recognition/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nhomnhom0/miniforge3/envs/face_recognition/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LoRaLin_KAN' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mKANLinear_EdgeFace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EdgeFace_KANLinear\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEdgeFace_KANLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m304\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_block_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSDTA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_path_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_scale_init_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpan_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_pos_embd_xca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_pos_embd_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43md2_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add any additional kwargs\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Print the model structure\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/KAN_EdgeFace/models/KANLinear_EdgeFace.py:63\u001b[0m, in \u001b[0;36mEdgeFace_KANLinear.__init__\u001b[0;34m(self, in_chans, num_classes, depths, dims, global_block, global_block_type, drop_path_rate, layer_scale_init_value, head_init_scale, expan_ratio, kernel_sizes, heads, use_pos_embd_xca, use_pos_embd_global, d2_scales, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_weights)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier_dropout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmul_(head_init_scale)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmul_(head_init_scale)\n",
      "File \u001b[0;32m~/miniforge3/envs/face_recognition/lib/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LoRaLin_KAN' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from models.KANLinear_EdgeFace import EdgeFace_KANLinear\n",
    "\n",
    "# Define the model\n",
    "model = EdgeFace_KANLinear(\n",
    "    in_chans=3, \n",
    "    num_classes=512,\n",
    "    depths=[3, 3, 9, 3],\n",
    "    dims=[48, 96, 160, 304],\n",
    "    global_block=[0, 0, 0, 3],\n",
    "    global_block_type=['None', 'None', 'None', 'SDTA'],\n",
    "    drop_path_rate=0.1, \n",
    "    layer_scale_init_value=1e-6, \n",
    "    head_init_scale=1.0, \n",
    "    expan_ratio=4,\n",
    "    kernel_sizes=[7, 7, 7, 7],\n",
    "    heads=[8, 8, 8, 8],\n",
    "    use_pos_embd_xca=[False, False, False, False],\n",
    "    use_pos_embd_global=False,\n",
    "    d2_scales=[2, 3, 4, 5],\n",
    "    classifier_dropout=0.5  # Add any additional kwargs\n",
    ")\n",
    "\n",
    "# Print the model structure\n",
    "print(model)\n",
    "\n",
    "# Alternatively, display a summary of the model\n",
    "summary(model, input_size=(3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
